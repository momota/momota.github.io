<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: gcp | momota.txt]]></title>
  <link href="http://momota.github.io/blog/categories/gcp/atom.xml" rel="self"/>
  <link href="http://momota.github.io/"/>
  <updated>2019-04-14T00:23:21+09:00</updated>
  <id>http://momota.github.io/</id>
  <author>
    <name><![CDATA[momota]]></name>
    <email><![CDATA[makoto.momota@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ねこの画像をランダムに表示する slack command]]></title>
    <link href="http://momota.github.io/blog/2019/04/13/slack-command/"/>
    <updated>2019-04-13T19:06:00+09:00</updated>
    <id>http://momota.github.io/blog/2019/04/13/slack-command</id>
    <content type="html"><![CDATA[<p>心の平穏のために、猫の画像をランダムに表示してくれる Slack command <code>/neko</code> を作った。</p>

<p>Slack で <code>/neko</code> と打つと、Cloud Functions にリクエストが飛び、Functions が <a href="https://thecatapi.com/">TheCatAPI</a> からランダムに猫画像 URL を取得するもの。</p>

<p><img src="/images/20190413_neko-slack-command/neko-command.png" alt="slack neko command" /></p>

<ul>
<li>参考

<ul>
<li><a href="http://momota.github.io/blog/2018/11/05/serverless-framework/">serverless framework による AWS Lambda ローカル開発 &ndash; momota.txt</a></li>
<li><a href="http://momota.github.io/blog/2019/04/06/slack-commands-by-cloud-functions/">Google cloud functions で slack (slash) commands をつくる &ndash; momota.txt</a></li>
</ul>
</li>
</ul>


<table>
<thead>
<tr>
<th> 使ったもの                  </th>
<th> 用途                </th>
</tr>
</thead>
<tbody>
<tr>
<td> Google Cloud Functions      </td>
<td> バックエンド        </td>
</tr>
<tr>
<td> Python 3.7                  </td>
<td> Functionsの実装言語 </td>
</tr>
<tr>
<td> Serverless framework 1.40.0 </td>
<td> GCPへのデプロイ     </td>
</tr>
</tbody>
</table>


<!-- more -->


<h2>Serverless framework の初期設定</h2>

<p>```sh</p>

<h1>create new service</h1>

<p>$ serverless create &mdash;template google-python &mdash;path neko</p>

<h1>go to the service directory</h1>

<p>$ cd neko</p>

<h1>install provider plugins</h1>

<p>$ npm install
```</p>

<p><code>serverless.yml</code> を自分の GCP 環境に合わせて編集する。</p>

<p>```yaml
service: neko</p>

<p>provider:
  name: google
  stage: dev
  runtime: python37
  region: YOUR-REGION
  project: YOUR-GCP-PROJECT-ID
  credentials: ~/.gcloud/YOUR-KEYFILE.json</p>

<p>plugins:
  &ndash; serverless-google-cloudfunctions</p>

<p>package:
  exclude:</p>

<pre><code>- node_modules/**
- .gitignore
- .git/**
</code></pre>

<p>functions:
  neko-command:</p>

<pre><code>handler: neko
events:
  - http: path
memorySize: 256
timeout: 60s
labels: {
    application: slack-slash-command,
    environment: development,
    owner: momota
</code></pre>

<p>}
```</p>

<h2>neko コマンドの実装</h2>

<p>まず <a href="https://thecatapi.com/">TheCatAPI</a> の API エンドポイントをコードの中に埋め込みたくないので、 <code>config.json</code> という外部ファイルに書き出し、実行時にそこから読み込むことにする。</p>

<p>以下のような感じ。</p>

<p>```json
{</p>

<pre><code>"API_URL": "https://api.thecatapi.com/v1/images/search?format=json"
</code></pre>

<p>}
```</p>

<p>Functions 用のコードは以下のような感じ。</p>

<p>```python
import json
import requests
from flask import jsonify</p>

<h1>外部ファイル config.json の読み込み</h1>

<p>with open(&lsquo;config.json&rsquo;, &lsquo;r&rsquo;) as f:</p>

<pre><code>data = f.read()
</code></pre>

<p>config = json.loads(data)</p>

<h1>TheCatAPI を叩いて、レスポンス (JSON) から 猫画像 URL を取得</h1>

<p>def neko_url():</p>

<pre><code>res = requests.get(config['API_URL'])
json_res = json.loads(res.text)
return json_res[0]['url']
</code></pre>

<h1>Slackへの応答フォーマットに整形</h1>

<p>def format_slack_message(message):</p>

<pre><code>return {
    'response_type': 'in_channel',
    'text': message
}
</code></pre>

<h1>Handler: Functions がリクエストを受けたときに実行する関数</h1>

<p>def neko(request):</p>

<pre><code>message = neko_url()
response = format_slack_message('ねこです ' + message)
return jsonify(response)
</code></pre>

<p>```</p>

<p>あとは GCP にデプロイして、Slack の Slash command の設定をすれば使える。</p>

<p><code>sh
$ serverless deploy -v
</code></p>

<h2>ちょっと頑張る： Slack トークン認証とエラーハンドリング</h2>

<p>Slack の Verification Token による簡易的な認証処理を追加する。</p>

<p>Slack command のApp設定から、Basic Information > App Credentials > Verification Token からトークンを取得して、<code>config.json</code> に書く。</p>

<p>```json
{</p>

<pre><code>"API_URL": "https://api.thecatapi.com/v1/images/search?format=json",
"SLACK_TOKEN": "YOUR-VERIFICATION-TOKEN"
</code></pre>

<p>}
```</p>

<p>以下のような処理を追加し、認証処理とエラーハンドリング処理を追加する。</p>

<p>とりあえず意図しないリクエストがバックエンド (Functions) にきたら、例外を投げる。</p>

<p>```python
def verify_request(request):</p>

<pre><code># POSTメソッドじゃない
if request.method != 'POST':
    raise Exception(405, 'Only POST requests are accepted')

# データが POST されていない
if not request.form:
    raise Exception(422, 'POST form is empty')

# POST データに ’token’ フィールドにない
if 'token' not in request.form:
    raise Exception(422, 'POST form is invalid')

# トークンがマッチしない
if request.form['token'] != config['SLACK_TOKEN']:
    raise Exception(403, 'Permission denied')
</code></pre>

<p>```</p>

<p>メイン処理側では、例外を補足したら、それに応じたエラーを返すように変更する。</p>

<p>```python
def neko(request):</p>

<pre><code>try:
    # validate request
    verify_request(request)

    message = neko_url()
    response = format_slack_message('ねこです ' + message)
    return jsonify(response)
except Exception as e:
    code, msg = e.args
    print('Exception occured: &lt;{}&gt; {}'.format(code, msg))
    return (msg, code)
</code></pre>

<p>```</p>

<h2>もうちょっと頑張る: 非同期処理</h2>

<p><a href="http://momota.github.io/blog/2019/04/06/slack-commands-by-cloud-functions/">前回</a>も述べたが、
Slack command は 3000 ms (3秒) 以内に応答しないとタイムアウトになってしまう。</p>

<p><a href="https://thecatapi.com/">TheCatAPI</a> のような外部 API に依存している場合、3 秒以内のレスポンスを保証できない可能性が高くなる。
そこで、バックエンドの Functions がリクエストを受けたら即時にレスポンスを返し、スレッドにより非同期で応答する。
Slack としても、そのような仕組みを支援するためにレスポンス用 URL を付与して、バックエンド側にリクエストを投げてくれる。</p>

<p>以下のようなイメージ。</p>

<p><img src="/images/20190413_neko-slack-command/seq.png" alt="change async sequence" /></p>

<p>スレッド処理のため、メイン処理を関数化し、レスポンス用 URL へ返答するよう書き換える。</p>

<p>```python
from threading import Thread</p>

<p>def neko_async(response_url):</p>

<pre><code>message = neko_url()
response = format_slack_message('ねこです ' + message)
post_data = json.dumps(response)

post_response = post_to_slack(response_url, post_data)
return
</code></pre>

<p>def neko(request):</p>

<pre><code>try:
    # validate request
    verify_request(request)

    # レスポンス用 URL の取得
    response_url = request.form['response_url']

    # スレッドで猫画像 URL処理を取得
    thread = Thread(target=neko_async, kwargs={'response_url': response_url})
    thread.run()

    return ''
except Exception as e:
    code, msg = e.args
    print('Exception occured: &lt;{}&gt; {}'.format(code, msg))
    return (msg, code)
</code></pre>

<p>```</p>

<p>最終的には以下のような感じになる。</p>

<p>```python
import json
import requests
from threading import Thread</p>

<h1>外部ファイル config.json の読み込み</h1>

<p>with open(&lsquo;config.json&rsquo;, &lsquo;r&rsquo;) as f:</p>

<pre><code>data = f.read()
</code></pre>

<p>config = json.loads(data)</p>

<h1>エラーハンドリングと簡易認証処理</h1>

<p>def verify_request(request):</p>

<pre><code># POSTメソッドじゃない
if request.method != 'POST':
    raise Exception(405, 'Only POST requests are accepted')

# データが POST されていない
if not request.form:
    raise Exception(422, 'POST form is empty')

# POST データに ’token’ フィールドにない
if 'token' not in request.form:
    raise Exception(422, 'POST form is invalid')

# トークンがマッチしない
if request.form['token'] != config['SLACK_TOKEN']:
    raise Exception(403, 'Permission denied')
</code></pre>

<h1>スレッド処理用関数</h1>

<p>def neko_async(response_url):</p>

<pre><code>message = neko_url()
response = format_slack_message('ねこです ' + message)
post_data = json.dumps(response)

post_response = post_to_slack(response_url, post_data)
return
</code></pre>

<h1>TheCatAPI を叩いて、レスポンス (JSON) から 猫画像 URL を取得</h1>

<p>def neko_url():</p>

<pre><code>res = requests.get(config['API_URL'])
json_res = json.loads(res.text)
return json_res[0]['url']
</code></pre>

<h1>Slackへの応答フォーマットに整形</h1>

<p>def format_slack_message(message):</p>

<pre><code>return {
    'response_type': 'in_channel',
    'text': message
}
</code></pre>

<h1>Slack レスポンス用 URL への POST処理</h1>

<p>def post_to_slack(url, post_data):</p>

<pre><code>post_headers = {
    'Content-type': 'application/json; charset=utf-8'
}

return requests.post(
    url,
    data=post_data,
    headers=post_headers
)
</code></pre>

<h1>Handler: Functions がリクエストを受けたときに実行する関数</h1>

<p>def neko(request):</p>

<pre><code>try:
    # validate request
    verify_request(request)

    response_url = request.form['response_url']
    thread = Thread(target=neko_async, kwargs={'response_url': response_url})
    thread.run()

    return ''
except Exception as e:
    code, msg = e.args
    print('Exception occured: &lt;{}&gt; {}'.format(code, msg))
    return (msg, code)
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google cloud functions で slack (slash) commands をつくる]]></title>
    <link href="http://momota.github.io/blog/2019/04/06/slack-commands-by-cloud-functions/"/>
    <updated>2019-04-06T09:19:00+09:00</updated>
    <id>http://momota.github.io/blog/2019/04/06/slack-commands-by-cloud-functions</id>
    <content type="html"><![CDATA[<p>Slack commands を Google Cloud Functions で実装する。</p>

<p>Slack commands は slack 上で <code>/command arguments</code> 形式で入力すると何かしらの応答を返す仕組み。<code>/</code> から始まるのでSlack Slash command とも呼ばれるようだ。
詳細は公式 API ページを参照: <a href="https://api.slack.com/slash-commands">Slash Commands | Slack</a></p>

<p><a href="http://momota.github.io/blog/2015/01/11/lita/">過去につくった Slack Bot</a> が動かなくなったので、GCP を利用して作り直そうというのが背景。</p>

<p>クラウドへのデプロイについては serverless framework を利用した。</p>

<ul>
<li>参考

<ul>
<li><a href="http://momota.github.io/blog/2015/01/11/lita/">lita で Slack Bot (on heroku) をつくる &ndash; momota.txt</a></li>
<li><a href="http://momota.github.io/blog/2018/11/05/serverless-framework/">serverless framework による AWS Lambda ローカル開発 &ndash; momota.txt</a></li>
</ul>
</li>
</ul>


<p>今回は、slack で <code>/ping</code> というコマンドを実行したら、<code>pong</code> と返すような slack command を作る。
できあがりは以下のような感じ。</p>

<p><img src="/images/20190406_slack-commands-by-cloud-functions/slack-ping-command.gif" alt="slack command screenshot" /></p>

<!-- more -->


<h3>事前設定</h3>

<p>serverless framework のインストール方法は <a href="http://momota.github.io/blog/2018/11/05/serverless-framework/">serverless framework による AWS Lambda ローカル開発 &ndash; momota.txt</a> を参照。</p>

<p>今回は、AWS Lambda (Javascript) ではなく GCP Cloud Functions (Python) を使う。</p>

<p>事前に GCP のクレデンシャル設定が必要となる。</p>

<ul>
<li>GCP クレデンシャル設定の詳細は公式を参照してほしい: <a href="https://serverless.com/framework/docs/providers/google/guide/credentials/">Serverless Framework &ndash; Google Cloud Functions Guide &ndash; Credentials</a></li>
<li>概要は以下。

<ol>
<li>請求先アカウントを作成</li>
<li>新規の Google Cloudプロジェクトを作成 (プロジェクトIDを控える)</li>
<li>必要な API を有効化。以下。

<ul>
<li>Google Cloud Functions</li>
<li>Google Cloud Deployment Manager</li>
<li>Google Cloud Storage</li>
<li>Stackdriver Logging</li>
</ul>
</li>
<li>クレデンシャルを入手する

<ul>
<li>サービスアカウントを作成</li>
<li>ロールの付与

<ul>
<li>Deployment Manager Editor</li>
<li>Storage Admin</li>
<li>Logging Admin</li>
<li>Cloud Functions Developer</li>
</ul>
</li>
<li>クレデンシャルキーファイルの作成 (keyfile.json)</li>
<li>キーファイルのデプロイ: <code>~/.gcloud/keyfile.json</code> など</li>
</ul>
</li>
</ol>
</li>
</ul>


<h3>serverless サービスの作成</h3>

<p>ここでは <code>ping</code> という名前でサービス (プロジェクトのようなもの) を作成する。</p>

<p>```sh
$ serverless create &mdash;template google-python &mdash;path ping
Serverless: Generating boilerplate&hellip;
Serverless: Generating boilerplate in &ldquo;/path-you-want/ping&rdquo;</p>

<hr />

<p>|   _   .&mdash;&mdash;&ndash;.&mdash;&mdash;.&mdash;.&mdash;.&mdash;&mdash;&ndash;.&mdash;&mdash;|  .&mdash;&mdash;&ndash;.&mdash;&mdash;&ndash;.&mdash;&mdash;&ndash;.
|   |<em><strong>|  &ndash;</strong>|   </em>|  |  |  &ndash;<strong>|   _|  |  &ndash;</strong>|<strong> &mdash;|</strong> &mdash;|
|<strong><strong>   |</strong></strong><em>|<strong>|  _</strong>/|</em><em><em><strong>|</strong>| |<strong>|</strong></em></em><em>|</em><strong><strong>|</strong></strong>_|
|   |   |             The Serverless Application Framework
|       |                           serverless.com, v1.40.0
 &mdash;&mdash;&mdash;&ndash;'</p>

<p>Serverless: Successfully generated boilerplate for template: &ldquo;google-python&rdquo;
```</p>

<p>作成したサービス名と同名のディレクトリが作成されるので、移動する。</p>

<p><code>sh
$ cd ping
</code></p>

<p>以下のファイルが自動生成されている。</p>

<p><code>sh
$ ls -la
合計 24
drwxr-xr-x 2 momota momota 4096  4月  2 22:45 .
drwxr-xr-x 5 momota momota 4096  4月  2 22:45 ..
-rw-r--r-- 1 momota momota  597  4月  2 22:45 .gitignore
-rw-r--r-- 1 momota momota  362  4月  2 22:45 main.py
-rw-r--r-- 1 momota momota  303  4月  2 22:45 package.json
-rw-r--r-- 1 momota momota 1431  4月  2 22:45 serverless.yml
</code></p>

<h3>プロバイダプラグインのインストール</h3>

<p>プロジェクトディレクトリで <code>npm install</code> する。</p>

<p><code>sh
$ npm install
</code></p>

<h3>プロバイダプロパティの更新</h3>

<p><code>serverless.yml</code> を編集する。</p>

<p><code>project</code> フィールドにGCP プロジェクト ID の指定するのと、<code>credentials</code> フィールドにcredentials ファイルの相対パスを指定する。
<code>functions</code> 以下の memorySize, timeout, labels はお好みで設定する。</p>

<p><code>handler</code> フィールドで指定している ping が後述する Python コードの関数名になっており、Cloud Functions 起動時に当該関数が呼び出される。</p>

<p>```yaml
service: ping</p>

<p>provider:
  name: google
  stage: dev
  runtime: python37
  region: us-central1
  project: YOUR-GCP-PROJECT-ID
  credentials: ~/.gcloud/YOUR-KEYFILE.json</p>

<p>plugins:
  &ndash; serverless-google-cloudfunctions</p>

<p>package:
  exclude:</p>

<pre><code>- node_modules/**
- .gitignore
- .git/**
</code></pre>

<p>functions:
  ping-command:</p>

<pre><code>handler: ping
events:
  - http: path
memorySize: 256
timeout: 60s
labels: {
    application: slack-slash-command,
    environment: production,
    owner: momota
}
</code></pre>

<p>```</p>

<h3>Functions コードの実装</h3>

<p>Slack から ping を受けたら pong を返す Python コードを書く。</p>

<p>Slack command が実行されとき Slack から送信されるリクエストは以下のようなフォーマットになっている。</p>

<p><code>
token=gIkuvaNzQIHg97ATvDxqgjtO
&amp;team_id=T0001
&amp;team_domain=example
&amp;enterprise_id=E0001
&amp;enterprise_name=Globular%20Construct%20Inc
&amp;channel_id=C2147483705
&amp;channel_name=test
&amp;user_id=U2147483697
&amp;user_name=Steve
&amp;command=/weather
&amp;text=94070
&amp;response_url=https://hooks.slack.com/commands/1234/5678
&amp;trigger_id=13345224609.738474920.8088930838d88f008e0
</code></p>

<p>これに対して、以下のような Json フォーマットでレスポンスを返す必要がある。</p>

<p>```json
{</p>

<pre><code>"response_type": "in_channel",
"text": "It's 80 degrees right now.",
"attachments": [
    {
        "text":"Partly cloudy today and tomorrow"
    }
]
</code></pre>

<p>}
```</p>

<p><code>main.py</code> を編集する。以下のようなコードになる。</p>

<p>```python
import json
from flask import jsonify</p>

<h1>ping を受けたら pong を返す関数</h1>

<p>def ping_command(query):</p>

<pre><code>return 'pong :table_tennis_paddle_and_ball:'
</code></pre>

<p>def format_slack_message(message):</p>

<pre><code>return {
    'response_type': 'in_channel',
    'text': message,
    'attachments': []
}
</code></pre>

<h1>Cloud Functions で起動される関数: メイン関数</h1>

<p>def ping(request):</p>

<pre><code># validate request
if request.method != 'POST':
    return 'Only POST requests are accepted', 405

message = ping_command(request.form['text'])
response = format_slack_message(message)

return jsonify(response)
</code></pre>

<p>```</p>

<p>Flask ライブラリに依存しているので、<code>requirements.txt</code> を作る。</p>

<p><code>sh
$ echo "Flask==1.0.2" &gt;&gt; requirements.txt
</code></p>

<h3>GCP へのデプロイ</h3>

<p><code>serverless deploy</code> により、GCS にソースコードがアップロードされ、Cloud Functions が Python 3.7 で起動する。
これはマネジメントコンソールからも確認できる。</p>

<p>```sh
$ serverless deploy -v                                <br/>
Serverless: Packaging service&hellip;
Serverless: Excluding development dependencies&hellip;
Serverless: Compiling function &ldquo;ping-command&rdquo;&hellip;
Serverless: Uploading artifacts&hellip;
Serverless: Artifacts successfully uploaded&hellip;
Serverless: Updating deployment&hellip;
Serverless: Checking deployment update progress&hellip;
&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;..
Serverless: Done&hellip;
Service Information
service: ping
project: YOUR-GCP-PROJECT-ID
stage: dev
region: us-central1</p>

<p>Deployed functions
ping-command
  <a href="https://us-central1-YOUR-GCP-PROJECT-ID.cloudfunctions.net/ping">https://us-central1-YOUR-GCP-PROJECT-ID.cloudfunctions.net/ping</a>
```</p>

<h3>slack の設定</h3>

<p><a href="https://api.slack.com/apps">Slack API： Applications | Slack</a> から <code>Create New App</code> ボタンをクリックしコマンドを作成する。</p>

<p>設定のやり方はこのあたりを参考にしたら良いと思う。: <a href="https://qiita.com/t-mimura/items/d6541ec596bdebea5a7b">Slackのコマンドを作ろう！！ &ndash; Qiita</a></p>

<p>command 作成時の <code>Request URL</code> に作成した Cloud Functions のエンドポイント <a href="https://us-central1-YOUR-GCP-PROJECT-ID.cloudfunctions.net/ping">https://us-central1-YOUR-GCP-PROJECT-ID.cloudfunctions.net/ping</a> を指定する。</p>

<p><img src="/images/20190406_slack-commands-by-cloud-functions/slack-config.png" alt="slack command config" /></p>

<p>Slack の設定が終わると、Slack から使えるようになる。</p>

<p><img src="/images/20190406_slack-commands-by-cloud-functions/slack-ping-command.gif" alt="slack command screenshot" /></p>

<p>Functions は初回起動時に少し時間がかかる。
Slack command は 3000 ms (3秒) 以内に応答しないとタイムアウトになってしまう。
タイムアウト時は Slack command を再実行してみたら良い。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[参加レポート]Google Cloud Kubernetes Day]]></title>
    <link href="http://momota.github.io/blog/2019/03/27/gc_k8sday/"/>
    <updated>2019-03-27T13:42:00+09:00</updated>
    <id>http://momota.github.io/blog/2019/03/27/gc_k8sday</id>
    <content type="html"><![CDATA[<ul>
<li>2019/03/26(火)、渋谷で行われた <a href="https://cloudplatformonline.com/2019-google-cloud-kubernetes-day-0326.html">Google Cloud Kubernetes Day</a> への参加レポート。</li>
<li>会場の約半数が k8s をすでに利用、サービスメッシュは1割程度という感じで、プロダクション環境での採用をやっていかないとまずいという雰囲気だった。</li>
<li>ハッシュタグ: <a href="https://twitter.com/hashtag/gc_k8sday">#gc_k8sday</a></li>
<li>資料が公開されたらリンクを張ったりアップデートする予定。</li>
</ul>


<!-- more -->


<h2>「Kubernetes/Container による開発」の導入難易度とメリット</h2>

<ul>
<li>株式会社サイバーエージェント　青山 真也 氏</li>
<li><p><a href="https://twitter.com/amsy810">@amsy810</a></p></li>
<li><p>サイバーエージェントとk8s</p>

<ul>
<li>早いところでは2016年頃からk8sを採用</li>
<li>GKEとオンプレの採用が多い (半々くらい)</li>
<li>オンプレミスでは独自のk8s as a Service基盤を構築</li>
<li>新規事業の多くがk8s/Containerを利用している</li>
<li>レガシーシステムからコンテナへの移行も実施中</li>
<li>事例

<ul>
<li><a href="https://speakerdeck.com/wappy100/legacy-to-container">レガシーシステムのコンテナ化に挑戦した話 / Legacy to Container &ndash; Speaker Deck</a></li>
<li><a href="https://speakerdeck.com/chokkoyamada/midoruuea-webapurimadequan-tewohelmhua-sitasabisufalseyun-yong-shi-li">ミドルウェア〜Webアプリまで全てをHelm化したサービスの運用事例 &ndash; Speaker Deck</a></li>
<li><a href="https://speakerdeck.com/masayaaoyama/saibaezientoniokerupuraibetokontenaji-pan-akewozhi-eruji-shu">サイバーエージェントにおけるプライベートコンテナ基盤AKEを支える技術 &ndash; Speaker Deck</a></li>
</ul>
</li>
</ul>
</li>
<li>k8s

<ul>
<li>コンテナオーケストレーションシステムの一つ</li>
<li>Google のクラスタマネージャ Borg ベースなので、Googleの経験がk8sに引き継がれている</li>
<li>現在はCNCFが中立的にホスト。コミュニティによって改良されている。</li>
</ul>
</li>
<li>オーケストレーションとは

<ul>
<li>プロビジョニングの一つ

<ol>
<li>ブートストラッピング: サーバの準備、OSのインストール

<ul>
<li>Terraform</li>
</ul>
</li>
<li>コンフィグレーション: サーバのセットアップ、ミドルウェアのインストール、セットアップ

<ul>
<li>Chef, Ansible, Puppet, Salt</li>
</ul>
</li>
<li>オーケストレーション: アプリケーションの配置

<ul>
<li>Fabric, Capistrano</li>
</ul>
</li>
</ol>
</li>
<li>イメージ化による高い再現性を保つようになってきた

<ul>
<li>Packer, Cloud Image, OpenStack Heat, CloudFormation</li>
</ul>
</li>
<li>容易なイメージ化、軽量なイメージ、高速な起動と停止。特定クラウドへの依存がない。

<ul>
<li>Docker, k8s</li>
</ul>
</li>
</ul>
</li>
<li>Cloud Nativeとは

<ul>
<li>疎結合なシステム</li>
<li>復元力がある</li>
<li>管理しやすい</li>
<li>可観測である</li>
<li>堅牢な自動化により、頻繁かつ期待通りに最小限の労力で大きな変更が可能</li>
</ul>
</li>
<li>CNCF が Cloud Native の進め方をTRAIL MAPとして定義: <a href="https://github.com/cncf/landscape">cncf/landscape</a></li>
</ul>


<p><img src="/images/20190327_gc_k8sday/cncf-trail-map.png" alt="CNCF trail map" /></p>

<h3>Containerization</h3>

<p>レガシーシステムのマイグレーションもスタート地点はここから。実行環境込みのアプリケーションをSystemdに置き換えるイメージ</p>

<ol>
<li>容易なイメージかと再現性 by Docker

<ul>
<li>アプリケーションと実行環境のイメージ化: 再現性の高い環境</li>
<li>OCI v1.0 によるポータビリティ</li>
<li>ローカル環境でも同等の動作が保証される</li>
</ul>
</li>
<li>軽量なイメージ by Docker

<ul>
<li>VMイメージと比べて軽量</li>
<li>単一プロセスのみを可動させるため、軽量OSの選定もしやすい: Alpine</li>
</ul>
</li>
<li>高速な起動と停止 by Docker

<ul>
<li>VMよりも起動停止が高速: プロセスの起動停止に相当</li>
<li>高速なスケールアウトや障害時の復旧が可能</li>
</ul>
</li>
</ol>


<h3>Orchestration</h3>

<ol>
<li>高い抽象度とクラウド非依存 by k8s

<ul>
<li>Load BalancerやStorageなども抽象化</li>
<li>利用者から見るとクラウド固有の知識がほぼ不要 vs Terraform, OpenStack heat, AWS CloudFormation</li>
<li>ベンダーニュートラルな実行基盤</li>
<li>基本的にはポータビリティがある</li>
</ul>
</li>
<li>宣言的なAPIとCode by k8s

<ul>
<li>構成情報はManifestsで宣言的に記述してAPIに登録: Infrastructure as Code

<ul>
<li><code>$ kubectl apply -f manifest.yaml</code></li>
</ul>
</li>
<li>Control LoopとReconciliation: 以下の処理を繰り替えす→ Control Loop

<ol>
<li>現在の状態を観測</li>
<li>現在の状態と理想状態を比較</li>
<li>差分に対する処理を実施 (Reconcilation)</li>
</ol>
</li>
</ul>
</li>
<li>洗練された自動化 by k8s

<ul>
<li>障害時のセルフヒーリング

<ul>
<li>ReplicaSet ではコンテナの Replica 数を維持し続ける</li>
<li>障害などでコンテナが不足した場合は、別の Node 上で高速に起動</li>
</ul>
</li>
<li>アプリケーションのアップグレード

<ul>
<li>ロードバランサからの除外</li>
<li>コンテナイメージのアップデート</li>
<li>ロードバランサへの追加</li>
</ul>
</li>
<li>コンテナ単位のヘルスチェック</li>
<li>コンテナ起動前の初期化処理</li>
<li>コンテナ停止時のSIGNAL</li>
<li>コンテナ開始直後、停止直前のフック</li>
</ul>
</li>
<li>豊富なエコシステムと拡張性 by k8s

<ul>
<li><img src="/images/20190327_gc_k8sday/cncf-landscape.png" alt="CNCF landscape" /></li>
<li>例
```yaml

<h1>MySQL Cluster on Kubernetes</h1>

<p>apiVersion: mysql.oracl.com/v1alpha1
kind: Cluster
metadata:
name: mysql
spec:
multiMaster: true
members: 3
```</p></li>
</ul>
</li>
</ol>


<p>```yaml</p>

<h1>CI/CD on Kubernetes</h1>

<p>apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: hello-world-
spec:
  entrypoint: whalesay
  templates:
  &ndash; name: whalesay</p>

<pre><code>container:
  image: docker/whalesay:latest
  command: [cowsay]
  args: ["hello world"]
</code></pre>

<p>```</p>

<p>```yaml</p>

<h1>Serverless on Kubernetes</h1>

<p>apiVersion: serving.knative.dev/v1alpha1
kind: Service
metadata:
  name: hello-world-go
  namespace: default
spec:
  runLatest:</p>

<pre><code>configuration:
  revisionTemplate:
    spec:
      container:
        image: docker.io/{username}/hello-world-go
        env:
        - name: TARGET
          value: "Go sample v1"
</code></pre>

<p>```</p>

<p>```yaml</p>

<h1>Service Mesh on Kubernetes</h1>

<p>apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: reviews
spec:
  hosts:</p>

<pre><code>- reviews
</code></pre>

<p>  <a href="http:">http:</a>
  &ndash; route:</p>

<pre><code>- destination:
    host: reviews
    subnet: v1
  weight: 50
- destination:
    host: reviews
    subnet: v3
  weight: 50
</code></pre>

<p>```</p>

<p>```yaml</p>

<h1>Managed Service via Kubernetes (Cloud SQL)</h1>

<p>apiVersion: servicecatalog.k8s.io/v1alpha1
kind: ServiceInstance
metadata:
  name: db
spec:
  clusterServiceClassExternalName: cloud-sql-mysql
  clusterServicePlanExternalName: beta
  parameters:</p>

<pre><code>instanceId: sample-cloudsql
databaseVersion: MYSQL_5_7
region: asia-northeast1
</code></pre>

<p>```</p>

<p>```yaml</p>

<h1>YOUR FEATURES with Kubernetes</h1>

<p>apiVersion: amsy.dev/v1beta1
kind: MyResource
metadata:
  name: my-resource
spec:
  name: MasayaAoyama
  replicas: 1
```</p>

<h3>Cloud Nativeの難しさ</h3>

<ol>
<li>アプリケーションのアーキテクチャ

<ul>
<li>マイクロ/ミニサービスに適した技術</li>
<li>いつでも停止できるようにSIGTERMのハンドリングは必須: ノードのアップグレード、コンテナイメージのアップデート</li>
<li>Service Discovery経由で通信</li>
<li>ネットワークに一部制約がある (Source IPが消失する、など)</li>
</ul>
</li>
<li>セキュリティと分離性

<ul>
<li>仮想化の分離性

<ul>
<li>runC (標準の Docker) では Kernel を共有</li>
<li>gVisorなど分離性の高い Container Runtime を利用する</li>
</ul>
</li>
<li>ネットワークの分離性

<ul>
<li>Network Policy を利用できない環境ではコンテナ間の通信は筒抜け</li>
</ul>
</li>
</ul>
</li>
<li>k8sの学習コスト

<ul>
<li>学習コストは小さくないものの懸念するほどではない</li>
</ul>
</li>
<li>k8sクラスタの運用

<ul>
<li>一番つらいのは k8s クラスタの管理

<ul>
<li>etcd のバックアップ</li>
<li>Kubernetes Master のスケールアップ</li>
<li>Kubernetes バージョンのアップグレード</li>
<li>Kubernetes クラスタのオートスケール</li>
<li>障害時のノード復旧</li>
<li>コンテナランタイム (Docker/ runC) の管理</li>
<li>OS (Kernel) の管理、など</li>
</ul>
</li>
<li>マネージド Kubernetes サービス GKE を利用することでだいぶ楽できる</li>
</ul>
</li>
</ol>


<h3>マネージドk8sの選定基準</h3>

<ul>
<li>マネージドの範囲</li>
<li>クラスタマネジメントの自動化機能</li>
<li>k8sバージョンの追随スピード</li>
<li>他のマネージド・サービスとのインテグレーション</li>
<li>ネットワーク周りの要件</li>
<li>その他: virtual-kubelet の対応など</li>
</ul>


<h3>サイバーエージェントと GKE</h3>

<ul>
<li>サイバーエージェントでは、アドテク分野やアベマTVなどいろいろなヘビーワークロードにもk8sで実装し、耐えうるシステムを構築</li>
<li>ステートフル部分はマネージドサービスを利用する: Cloud Storage, Cloud SQL、BigQuery、…</li>
</ul>


<h2>コンテナ開発プラットフォームに GKE を選択すべき 7 つの理由</h2>

<ul>
<li>Google Cloud Japan　田中 宏樹氏、岩成 祐樹氏</li>
</ul>


<h3>Security</h3>

<ul>
<li>セキュリティがクラウドの長所に</li>
<li><p>GCPでは、徹底的な防御がデフォルトでON</p>

<ul>
<li>通信の暗号化</li>
<li>ストレージの暗号化</li>
<li>認証・認可</li>
<li>ハードウェア</li>
</ul>
</li>
<li><p>コンテナのセキュリティとは</p>

<ul>
<li>インフラストレクチャセキュリティ: インフラはコンテナを開発するのに安全か

<ul>
<li>k8s のセキュリティ機能を使って、ID, シークレット, ネットワークをどのように守るか</li>
<li>GKEに備わるIAM, audit logging, networkingなどの機能をどのように活用するか</li>
</ul>
</li>
<li>ソフトウェアサプライチェーン: 作成したコンテナはビルド、デプロイして問題ないか

<ul>
<li>コンテナイメージに脆弱性がないことをどのように保証するか</li>
<li>ビル出されたイメージが、デプロイまでに改ざんされないことをどのように保証するか</li>
</ul>
</li>
<li>ランタイムセキュリティ: 作成したコンテナは実行して問題ないか

<ul>
<li>コンテナが不審な挙動をしたときにどのように検知するか</li>
<li>その際、ワークロードをどのように守り、分離するか</li>
<li>どのようにコンテナのデプロイを安全にスケールさせるか</li>
</ul>
</li>
</ul>
</li>
<li><p>コンテナセキュリティの脅威とリスク</p></li>
</ul>


<table>
<thead>
<tr>
<th>インフラストラクチャセキュリティ </th>
<th> ソフトウェアサプライチェーン     </th>
<th> ランタイムセキュリティ</th>
</tr>
</thead>
<tbody>
<tr>
<td>権限昇格                         </td>
<td> パッチ適用漏れによる脆弱性       </td>
<td> DDoS</td>
</tr>
<tr>
<td>機密情報の漏洩                   </td>
<td> サプライチェーンに聞いする脆弱性 </td>
<td> Node への不正アクセス</td>
</tr>
<tr>
<td>Kubernetes API の漏洩            </td>
<td> 共通ライブラリのゼロデイ脆弱性   </td>
<td> Container escape</td>
</tr>
<tr>
<td>必要以上の権限を持つユーザ       </td>
<td>                                  </td>
<td> Flood event pipline</td>
</tr>
</tbody>
</table>


<ul>
<li>コンテナのセキュリティ

<ul>
<li>GKE: Use RBAC and IAM

<ul>
<li>プロジェクトレベルでIAMを利用</li>
<li>クラスタ/ネームスペースレベルでRBACを利用</li>
</ul>
</li>
<li>プライベートクラスタと承認済みネットワーク</li>
<li>Cloud Armor: スケーラブルなDDoS対策/WAF</li>
<li>BackendConfg

<ul>
<li>Kubernetes Engine Ingress controller で利用されるカスタムリソース定義</li>
<li>BackendConfig オブジェクトとサービスポートを紐付けることで、GCLB 用の設定が可能</li>
<li>GKE version 1.10.5-GKE.3 以降で利用可能</li>
</ul>
</li>
<li>ソフトウェアサプライチェーン

<ul>
<li>CI/CDパイプラインは信頼できないデプロイを止めてくれない

<ul>
<li>イメージのメタデータ</li>
<li>Binary Authorization: QAされたコードだけを実行</li>
</ul>
</li>
<li>Container Registry: 脆弱性スキャン

<ul>
<li>Ubuntu, Debian, Alpineのパッケージにある脆弱性を特定</li>
<li>常時更新されるデータベースにより、スキャンが常に最新であることを保証</li>
<li>検出可能な脆弱性を拡張するために、既存のツールをプラグインすることが可能</li>
</ul>
</li>
<li>Binary Authorization: 信頼されたコンテナイメージのみをGKE上にデプロイすることを保証するセキュリティコントロール機能

<ul>
<li>検証済みイメージのみが、ビルドリリースプロセスと統合可能</li>
<li>開発中に信頼された認証局により署名されたイメージが必要となる</li>
<li>Kubernetes Engineにデプロイする前にシグネチャの検証を矯正することが可能</li>
</ul>
</li>
</ul>
</li>
<li>ランタイムセキュリティ

<ul>
<li>Container Optimized OS: GCE, GKEで利用可能な軽量なイメージ

<ul>
<li>runcの脆弱性 CVE-2019-5736の影響を受けなかった</li>
</ul>
</li>
<li>Runtime security partners in Cloud SCC: 3rdパーティツールの利用

<ul>
<li>Cloud Security Command Center</li>
<li>aqua, capsule8, stackrox, sysdig, twistlock&hellip;</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>Network</h3>

<ul>
<li>さまざまなGCPサービスとの統合</li>
<li>Google Cloud Load Bakancing

<ul>
<li>世界で一つのエニーキャストアドレスに対するリクエストを、複数のリージョンにまたがってデプロイされたGKEクラスタに対してルーティングすることが可能</li>
</ul>
</li>
<li>世界中のCloud CDNとLB

<ul>
<li>9 つのリージョン、27 のゾーン、100 以上の接続ポイント（POP）、および延べ数十万 km に及ぶ光ファイバーケーブルで構築され、適切にプロビジョニングされたグローバルネットワーク</li>
</ul>
</li>
<li>Container Native Load Balancing

<ul>
<li>LBからVM(Node)を介さずPodへ直接トラフィックを転送</li>
<li>Double-hop問題を解決</li>
<li>レイテンシーとルーティング性能問題を解決</li>
<li>VPC-native clusters かつ Kubernetes version 1.10+ で利用可能</li>
</ul>
</li>
</ul>


<h3>Hybrid Cloud</h3>

<ul>
<li>ゴール: コードをどこでも実行できる環境を整える</li>
<li>GKE On-prem

<ul>
<li>オンプレミスのクラスタをGoogle Cloud Consoleから一元的に管理</li>
<li>クラスタ集中管理のメリット: GKEとGKE On-Premで同じツールを使ってクラスタの構築、構成、管理を実施</li>
<li>同一のクラスタ環境</li>
</ul>
</li>
<li>事例

<ul>
<li>メルカリ: オンプレミスからの移行</li>
</ul>
</li>
</ul>


<h3>Observability</h3>

<ul>
<li>ロギング

<ul>
<li>複数のアプリケーションやサービスから発生するログの収集</li>
<li>GCP内部の情報に加えて、GCPの外部で発生するログについても収集できる基盤が必要</li>
</ul>
</li>
<li>モニタリング

<ul>
<li>収集したtログや指標を見える化し、アクションを提供する一連のプロセス</li>
<li>アプリケーションのエラーが発生したり、しきい値を超えた際に、アラートを適切な担当者に正しく送る機能が必要</li>
</ul>
</li>
<li>統合管理プラットフォーム

<ul>
<li>DevOpe/SRE: パフォーマンスの問題を調査するためには、すべてのクラスターの状況の理解が必要</li>
<li>Developer: 最良のシステムを構築するためには、インフラストラクチャ、ワークロード、サービスを継続モニタリングが必要</li>
<li>SecOps: セキュリティポリシーを見直してコンプライアンスを強化のため、すべてのクラスタの監査ログの収集が必要</li>
</ul>
</li>
<li>Stackdriver: アプリケーション開発者と運用担当者にLoggingとMonitoring機能を提供する</li>
<li>Stackdriver Kubernetes Monitoring

<ul>
<li>k8sのワークロードに最適化されたStackdriverのツール</li>
</ul>
</li>
<li>work with Open Source: Prometheus

<ul>
<li>Google にインスパイアされたエンジニアが Prometheus イニシアティブをリード</li>
<li>Open Source の Prometheus と、Stackdriver k8s Monitoring のシームレスなインテグレーション</li>
</ul>
</li>
</ul>


<h3>Contribution</h3>

<ul>
<li>Open source is free like a puppy</li>
<li>GKE is going to ..

<ul>
<li>To be Reliable

<ul>
<li>Regional clusters

<ul>
<li>Kubernetes コントロールプレーンを3つのゾーン (同一リージョン) で実行する</li>
</ul>
</li>
<li>Regional Persistent Disks

<ul>
<li>セカンダリゾーンの Disk に対してデータをミラーリング</li>
<li>ゾーン障害時、GKEはコンテナを問題のないゾーンにマイグレーション、強制的にミラーリングしてある Disk をアタッチ</li>
</ul>
</li>
</ul>
</li>
<li>To be Scalable

<ul>
<li>HPA: Pod の水平スケーリング</li>
<li>VPA: Pod の垂直スケーリング</li>
<li>CA: Node の水平スケーリング</li>
<li>Node Auto-Provisioning</li>
</ul>
</li>
<li>To be Open

<ul>
<li>OSS Friendly ecosystem

<ul>
<li>Skaffold</li>
<li>Kanico</li>
<li>Knative</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>GKE を用いたレガシー システムからのリプレース事例</h2>

<ul>
<li>富士フイルム株式会社　小林 大助 氏</li>
</ul>


<h3>プロジェクト概要</h3>

<ul>
<li>FUJIFILM Prints &amp; Gifts

<ul>
<li><a href="https://pg-ja.fujifilm.com/photo-print">写真プリント | FUJIFILMプリント＆ギフト | 富士フイルムの公式ストア</a></li>
<li><a href="https://fujifilmmall.jp/walldecor/?_ga=2.101125698.254826136.1553583454-463832683.1553583454">WALL DECOR（ウォールデコ）｜富士フイルム</a></li>
</ul>
</li>
<li>レガシーシステム運用10年超え

<ul>
<li>保守・運用コスト大</li>
<li>機能改善スピード低</li>
</ul>
</li>
<li>ユーザの消費動向の変化

<ul>
<li>モノ消費からコト消費へ</li>
</ul>
</li>
</ul>


<h3>GKE利用までの経緯</h3>

<ul>
<li>S→T→P→D→C→A

<ul>
<li>PDCAに加えて See + Think</li>
<li>富士フィルムではSTを重視</li>
<li>現状分析をしっかり行い、目的を明確にする</li>
</ul>
</li>
<li>モノリシックなアプリケーションにより影響範囲の見定めが難しい</li>
<li>特に苦労しているのは季節イベント、キャンペーン

<ul>
<li>負荷量の変動に対してシステムが追随しにくい</li>
<li>スケーラビリティを確保しやすい仕組みを最優先にする</li>
<li>コンテナを採用</li>
</ul>
</li>
<li>保守面を意識すれば、オーケストレーションツールは使いたい。課題が2つ

<ul>
<li>何が標準か

<ul>
<li>流行度</li>
<li>[社内の]覇権争い</li>
<li>仕様策定中</li>
</ul>
</li>
<li>自分たちで運用できるか

<ul>
<li>使いこなせないと意味がない</li>
<li>運用環境に耐えうるレベルか</li>
</ul>
</li>
</ul>
</li>
<li>k8sがデファクトスタンダードになった: 規格争いによる技術の陳腐化懸念が後退</li>
<li>主要ベンダがk8sマネージドサービスを展開: コンテナやオーケストレーションツールが動作する環境を自前で準備する必要がなくなり、安定動作する環境が整いつつある

<ul>
<li>2018年1月時点で日本国内GAしているのはGoogeのみ</li>
<li>動作安定性: k8s の開発元であること、コンテナを先取りしている取り組み、4年以上の安定動作運用実績があることから信頼性が高い。完全にコンテナ化できない部分でもライブマイグレーション機能の強みを活かせる</li>
</ul>
</li>
</ul>


<h3>取り組む上での課題: 組織面</h3>

<ul>
<li>周囲の理解

<ul>
<li>コンテナやオーケストレーションツールに対する周囲の理解を深めなければならない</li>
<li>技術的優位性を説明できないといけない</li>
<li>総論は賛成、各論は？</li>
<li>リスクを背負えるか: 納期遵守のPrj</li>
<li>所属部門・関係部門の合意を取り付ける必要あり</li>
</ul>
</li>
<li>近道はなし: 技術学習、解説資料作成、説明行脚</li>
<li>現場レベルでは味方は多かった: 技術学習の協力や相談が効率化。求めるところが同じがゆえの連帯感。

<ul>
<li>プロジェクトメンバー</li>
<li>インフラエンジニア</li>
<li>部門横断のエンジニア</li>
</ul>
</li>
<li>リスクに対しては、バックアッププランの準備、技術習得状況の説明、Googleエンジニアのバックアップ</li>
</ul>


<h3>取り組む上での課題: 開発面</h3>

<ul>
<li>技術習得: 独学とハンズオン</li>
<li>事前調査

<ul>
<li>レガシーシステムのルール把握: どの程度引きずられるか、実施してから発覚した問題あり</li>
<li>効率的なシステム間連携に知識が必要

<ul>
<li>Pub/Sub 連携のイベント発火条件も当初は無駄が多かったプログラムか、サービス活用かの見極め

<ul>
<li>当初案: プログラム制御でイベント発火</li>
<li>対応案: ファイル配置 → Cloud Functions で配置イベント検知 → Pub/Sub 投げ込み、のように分離</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>運用: ログ出力やアラート関連は、メトリクスの書き方が困難だった</li>
<li>設計・設定: マニフェストファイルの書き方、永続データの取扱いに関する適切なサービス選定がむずい</li>
<li>基本設計: サービス分割はアトミックにすると障害復旧が難しいので、意味のある塊に</li>
<li>商用利用に向けての課題: PaaSの特徴や仕様についてGoogleエンジニアのサポートを受けながら選定、確認を進める</li>
<li>レガシーシステムとの連携

<ul>
<li>レガシーシステム側を変えることは難しく、ルールに従う必要あり (IP制限、連携方法の指定など)</li>
<li>基本は新システム側が全面降伏で対応: もともと予定していなかったインフラ構築やネットワーク設定が追加</li>
</ul>
</li>
</ul>


<h3>効果</h3>

<ul>
<li>スケーラビリティの確保はできた。ただし、今後悪化しないように管理していく必要がある</li>
<li>保守運用コストは改善された

<ul>
<li>モノリシックな構造を改善し、影響範囲を縮小できた。機能搭載費用 1/2に</li>
<li>サーバリソースの有効活用によりランニングコスト 3/5に</li>
<li>導入8ヶ月でサービスダウンタイムなし。安定稼働中。</li>
</ul>
</li>
<li>機能改善スピードは向上できた

<ul>
<li>対応速度が約2倍に</li>
</ul>
</li>
<li>学習コストは小さくなかったが、リターンが大きかった</li>
<li>アプリ開発に集中できる環境を整えることができた</li>
<li>組織の壁は高い、乗り越えるには熱意が必要。仲間がいれば突破しやすい</li>
<li>クラウドベンダエンジニアの協力は偉大</li>
</ul>


<h2>コンテナによる開発と運用の進化</h2>

<ul>
<li><p>Google Cloud Japan　篠原 一徳氏、村上 大河氏</p></li>
<li><p>3つのポイント</p>

<ul>
<li>人 (ビジネス・技術)

<ul>
<li>CxO</li>
<li>Manager</li>
<li>Business</li>
<li>Tech</li>
</ul>
</li>
<li>プロセス

<ul>
<li>DevOps</li>
<li>SRE</li>
<li>Scrum (アジャイル開発)</li>
<li>Waterfall</li>
</ul>
</li>
<li>テクノロジー

<ul>
<li>クラウド</li>
<li>マイクロサービスアーキテクチャ</li>
<li>CI/CD</li>
</ul>
</li>
</ul>
</li>
<li>マイクロサービスとは

<ul>
<li>2014年にJames LewisとMartin Fowlerが提唱</li>
<li>機能ごとに独立したアプリケーションに分割</li>
<li>各サービスは単一の目的を持つ</li>
<li>分散システム、サービス間は疎結合、軽量なAPIなどでやりとり</li>
</ul>
</li>
<li>AsIs to ToBe: Monolith to Microservice

<ul>
<li>新規サービスからやる (新規機能から抜き出す)</li>
<li>既存のサービスを部分的に置き換える

<ul>
<li>Domain (専門領域) を抜き出し、マイクロサービス化する</li>
<li>チームも抜き出していくことが重要</li>
</ul>
</li>
</ul>
</li>
<li>マイクロサービス化を進めていくと、カオス化</li>
<li>The problem

<ul>
<li>分散アーキテクチャへの移行により、今までのアーキテクチャ向けに最適化された方法では監視、管理、保護が困難</li>
</ul>
</li>
<li>4 challenges of Microservices

<ul>
<li>プロセス内のコミュニケーションから、プロセス外コミュニケーションへの置き換え: RPC + APIゲートウェイ</li>
<li>分散システム導入により複雑化するシステムの効率的な管理: サービスメッシュ</li>
<li>マイクロサービス協会が引き起こすデータサイロの解決: データレイク</li>
<li>アプリケーションコード以外のコーディングを少なくする: 自動化 (CI/CD)</li>
</ul>
</li>
<li>課題と2つの実現方法

<ul>
<li>呼び出し先マイクロサービスのトラッキングが困難

<ul>
<li>REST API (HTTP1.1)

<ul>
<li>Open APIでメッセージフォーマットを定義</li>
<li>互換性管理のためのガイドラインの作成を推奨</li>
</ul>
</li>
<li>gRPC (HTTP2.0)

<ul>
<li>Protocol Buffersでメッセージフォーマットを定義</li>
<li>Language Guideに従うと、下位互換性の担保が容易</li>
</ul>
</li>
</ul>
</li>
<li>バージョン管理ガイド

<ul>
<li><a href="https://cloudplatform-jp.googleblog.com/2017/07/versioning-APIs-at-Google.html">Google Cloud Platform Japan 公式ブログ： Google における API のバージョニング</a></li>
<li>Google 内部のAPIバージョニング手法を公開</li>
<li>Cloud Endpointで実現をサポート</li>
</ul>
</li>
<li>API設計ガイド

<ul>
<li><a href="https://cloud.google.com/apis/design/">API 設計ガイド | Cloud API | Google Cloud</a></li>
<li>Google内部のAPI設計のスタンダードを公開</li>
<li>Cloud Endpointで簡単に実現</li>
</ul>
</li>
<li>Cloud Endpointsによるマイクロサービスの実現

<ul>
<li>内部はgRPC、外部はRESTで公開も可能</li>
</ul>
</li>
</ul>
</li>
<li>サービスメッシュ

<ul>
<li>マイクロサービス環境において、サービスディスカバリ、トラフィックコントロール、認証・認可、メトリクス収集などの機能を担うソフトウェア</li>
<li>アプリケーション自体に手を入れるのではなく、サイドカーで実現</li>
<li>Istio: GoogleとIBMが中心に開発しているサービスメッシュ実装のOSS

<ul>
<li>ProxyとしてEnvoyを利用</li>
<li>トラフィックコントロール

<ul>
<li>これまでトラフィックコントロールはインフラストラクチャと結びついていた</li>
<li>トラフィックスプリッティング</li>
</ul>
</li>
<li>セキュリティ

<ul>
<li>サービス間のセキュリティを強化</li>
<li>RBAC</li>
</ul>
</li>
<li>可観測性

<ul>
<li>Istioの監視

<ul>
<li>Mixer: テレメトリの収集</li>
<li>Prometheus: Mixer から提供される Istio メトリクスの保存と検索</li>
<li>Grafana: ダッシュボードでメトリクスの可視化</li>
<li>Jaeger: トレース情報の取得</li>
<li>Kiali (addon): サービスグラフの管理</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Istio on GCP</li>
</ul>
</li>
<li>データレイク

<ul>
<li>マイクロサービスにより、データのサイロ化が進む</li>
<li>そのとき、どのようにデータを伝送すればよいか</li>
<li>また、ビジネス要件である分析も行いたい</li>
</ul>
</li>
<li>CSM (Managed Istio) の Alphaユーザを募集中: <a href="https://docs.google.com/forms/d/1Qhj4qViWgaSAf9KUfowWRdVS6OHwg9cgEdYX2xbpLeM/viewform?edit_requested=true">https://docs.google.com/forms/d/1Qhj4qViWgaSAf9KUfowWRdVS6OHwg9cgEdYX2xbpLeM/viewform?edit_requested=true</a></li>
</ul>


<h2>FreakOut の広告プロダクトでの GKE 活用事例と GKE 新機能の導入について</h2>

<ul>
<li><p>株式会社フリークアウト　西口 次郎 氏</p></li>
<li><p>RED: Freakout DSP</p></li>
<li>ASE: 位置情報マーケティングプラットフォーム</li>
<li>RED for Publishers: アドネットワーク基盤</li>
<li>LayApp: アプリエンゲージメントプラットフォーム</li>
</ul>


<h3>プロダクション環境でのGKE運用</h3>

<ul>
<li><a href="https://cloudplatform-jp.googleblog.com/2018/09/freakout-kubernetes-engine.html">Google Cloud Platform Japan 公式ブログ： 株式会社フリークアウトの導入事例： フルマネージドな Kubernetes Engine を駆使して、大規模アドプラットフォームをプレミアム メディア向けに提供</a></li>
<li>GKE

<ul>
<li>サービスごとにクラスタを分割</li>
<li>広告配信、UI、バッチ</li>
<li>CronJob (>= k8s 1.8) を利用</li>
<li>カナリーリリース環境を用意</li>
<li>Stackdriverを活用</li>
</ul>
</li>
<li>Stackdriver

<ul>
<li>Monitoring

<ul>
<li>Prometheusと併用</li>
<li>Grafana 5.3 で Stackdriver Datasource を利用中</li>
</ul>
</li>
<li>Logging

<ul>
<li>コンテナのエラーログなどを集約</li>
<li>アラート: Pub/Sub → Cloud Functions → Slack</li>
</ul>
</li>
<li>Profiler

<ul>
<li>常に最新のコードのプロファイルを可視化、比較</li>
</ul>
</li>
</ul>
</li>
<li>BigQuery

<ul>
<li>すべてのアクセスログ、アプリケーションログを集約

<ul>
<li>数十億レコード/日</li>
</ul>
</li>
<li>fluentd (Sidecar Container)からStreaming insert

<ul>
<li>リアルタイム集計</li>
</ul>
</li>
<li>可視化はre:dashを利用</li>
<li>MySQLのマスタデータもインポートしている</li>
</ul>
</li>
<li>Vulnerability scanning

<ul>
<li>GCRの機能</li>
<li>Debian, Ubuntu, Alpineが対象</li>
<li>過去30日間にpullされたイメージが対象</li>
<li>脆弱性が見つかった際、Pub/SubにPublishされる (Cloud FunctionsでSlack通知)</li>
</ul>
</li>
<li>kustomise

<ul>
<li>k8s のYAMLファイルのカスタマイズ</li>
<li>kubectrlのサブコマンドとしてマージされた</li>
<li>Production/Staging/Cannaryなど環境ごとの設定を上書き

<ul>
<li>Replicas</li>
<li>環境変数</li>
<li>ConfigMap</li>
</ul>
</li>
</ul>
</li>
<li>Other tools

<ul>
<li>stern

<ul>
<li>複数のコンテナのログをすばやく確認できる</li>
</ul>
</li>
<li>kubectx

<ul>
<li>クラスタ切り替え</li>
<li>複数クラスタ/開発・本番環境の切り替えに</li>
<li>ネームスペースの切り替えも可能</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>GKEでのCI/CD</h3>

<ul>
<li>Github</li>
<li>CircleCI</li>
<li>Cloud Build</li>
<li>Cloud Container Registry</li>
<li>Cloud Pub/Sub: ビルド通知</li>
<li>Cloud Functions: Slack通知</li>
<li>Slack: エンジニア通知</li>
</ul>


<h4>CIのフロー</h4>

<ol>
<li>GithubへのPush</li>
<li>テスト・ビルド

<ul>
<li>CircleCIでのテスト</li>
<li>CloudBuildでのビルド</li>
</ul>
</li>
<li>カナリアリリース</li>
</ol>


<h4>CDのフロー</h4>

<ol>
<li>GithubでPRをマージ</li>
<li>ビルド&amp;デプロイ

<ul>
<li>docker build</li>
<li>docker push (to Container Registry)</li>
<li>kubectrl set image</li>
</ul>
</li>
<li>notification

<ul>
<li>Pub/SubへのPublish</li>
<li>Cloud FunctionsでSlack通知</li>
</ul>
</li>
</ol>


<h3>GKE 新機能の利用</h3>

<ul>
<li>VPC-native cluster (alias IP)

<ul>
<li>Cloud Memorystore for Redis の利用が可能</li>
<li>Cloud SQL Private IP に接続可能</li>
</ul>
</li>
<li>Cloud NAT

<ul>
<li>マネージドNATサービス</li>
<li>アウトバウンドアクセスのゲートウェイ</li>
<li>外部アクセスするIPアドレスを限定する用途で使用

<ul>
<li>IPアドレスの事前登録が必須な外部API</li>
</ul>
</li>
</ul>
</li>
<li>Network Endpoint Groups (NEGs)

<ul>
<li>コンテナネイティブの負荷分散</li>
<li>Instance Groupはiptablesを介してPodへルーティングしていたが、Podへ直接ルーティング可能</li>
<li>ネットワークパフォーマンス改善</li>
<li>要 VPC-native cluster</li>
<li>Service アノテーション <code>cloud.google.com/neg</code> に <code>{ "ingress": true }</code> を指定する</li>
</ul>
</li>
<li>BackendConfig Custom resource

<ul>
<li>GKE Ingressコントローラのカスタムリソース定義

<ul>
<li>Balancer Settings</li>
<li>Cloud Armor</li>
<li>Cloud IAP</li>
<li>Cloud CDN</li>
</ul>
</li>
<li>Service と BackendConfig を紐づけて使用する

<ul>
<li>Service アノテーション <code>beta.cloud.google.com/backend-configs</code></li>
</ul>
</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[参加レポート]GDG-Tokyo New Year Party 2019]]></title>
    <link href="http://momota.github.io/blog/2019/01/31/gdg-tokyo/"/>
    <updated>2019-01-31T10:51:00+09:00</updated>
    <id>http://momota.github.io/blog/2019/01/31/gdg-tokyo</id>
    <content type="html"><![CDATA[<p><img src="/images/20190131_gdg-tokyo/gdg.png" alt="GDF-Tokyo New Year Party logo" /></p>

<ul>
<li>2019/01/30(水)、六本木で行われた<a href="https://gdg-tokyo.connpass.com/event/113178/">GDG Tokyo New Year Party 2019 &ndash; connpass</a> への参加レポート。</li>
</ul>


<!-- more -->


<h3>How to start Android Dev</h3>

<script async class="speakerdeck-embed" data-slide="1" data-id="5e83e4faafc34fb6a4dcacdb633f47ea" data-ratio="1.77777777777778" src="http://momota.github.io//speakerdeck.com/assets/embed.js"></script>


<ul>
<li>発表者: <a href="https://twitter.com/wasabeef_jp">@wasabeef_jp さん</a></li>
<li>資料: <a href="https://speakerdeck.com/wasabeef/jp-how-to-start-android-dev">［JP］ How to start Android Dev &ndash; Speaker Deck</a></li>
</ul>


<h4>IDE (Build tool)</h4>

<ul>
<li>Android Studio

<ul>
<li>Layout Editor</li>
<li>MotionLayout: Motion editor</li>
<li>Emulator: 数年前に比べると高機能・高速化</li>
</ul>
</li>
<li>Gradle

<ul>
<li>ビルド自動化</li>
<li>Android開発におけるスタンダード</li>
<li>DSL (デフォルトGroovy DSL)

<ul>
<li>Kotlin DSL</li>
</ul>
</li>
</ul>
</li>
<li>Java / Kotlin

<ul>
<li>近年はKotlinが主流

<ul>
<li>Libraryを作るときはJavaで作ることが多い</li>
</ul>
</li>
<li>Java 8: 最新のJavaは使えない

<ul>
<li>D8 toolsによって今後変わりそう</li>
</ul>
</li>
<li>Kotlin 1.3

<ul>
<li>Coroutines: 軽量スレッド</li>
<li>Null-safety</li>
<li>Extention functions</li>
<li>Lambda + Inline functions、など</li>
</ul>
</li>
</ul>
</li>
</ul>


<h4>Architecture</h4>

<ul>
<li>MVVM

<ul>
<li>Google推奨でAACと相性がいい</li>
</ul>
</li>
<li>Flux

<ul>
<li>日本で数件の事例あり</li>
</ul>
</li>
</ul>


<h4>Jetpack</h4>

<ul>
<li>KTX

<ul>
<li>Core</li>
<li>Fragment</li>
<li>Lifecycle</li>
</ul>
</li>
<li>Lifecycles

<ul>
<li>バックグラウンド状態、フォアグラウンド状態、電源状態…</li>
<li>ライフサイクルを知りたいとき

<ul>
<li>動画の開始停止</li>
<li>画面閉じたときの終了処理</li>
</ul>
</li>
</ul>
</li>
<li>ViewModel (+ LiveData)

<ul>
<li>Activity/ViewModelはそれぞれ異なるライフサイクルがあるが、ViewModelのほうが長生きする</li>
<li>ViewModel

<ul>
<li>Activityの画面回転・破棄のデータ保持</li>
<li>Fragments感のデータ共有</li>
<li>永続化ではない</li>
</ul>
</li>
</ul>
</li>
<li>Navigation

<ul>
<li>Fragment Transactionの簡易化

<ul>
<li>アニメーション</li>
</ul>
</li>
<li>ディープリンク</li>
<li>Navigation Editor</li>
</ul>
</li>
</ul>


<h4>DI</h4>

<ul>
<li>Dagger

<ul>
<li>Java</li>
</ul>
</li>
<li>Koin</li>
<li>Kodein</li>
</ul>


<h4>Networking</h4>

<ul>
<li>Retrofit</li>
</ul>


<h4>Testing</h4>

<ul>
<li>Unit Test

<ul>
<li>Instrument Test: 実機テスト</li>
<li>Local Test (Robolectric): CIとの相性がいい</li>
<li>Firebase Test Lab</li>
</ul>
</li>
</ul>


<h4>CI</h4>

<ul>
<li>bitrise

<ul>
<li>モバイル向け</li>
</ul>
</li>
<li>CircleCI

<ul>
<li>高機能</li>
<li>メモリ不足で落ちる場合がある</li>
</ul>
</li>
<li>Danger

<ul>
<li>コードレビューの自動化をCI上で</li>
</ul>
</li>
</ul>


<h4>Flutter</h4>

<ul>
<li>Google製</li>
<li>Hot reload</li>
<li>ウィジェットがたくさん</li>
</ul>


<h3>Cloud Functionsから始めるFirebase</h3>

<script async class="speakerdeck-embed" data-slide="1" data-id="161fd22794824e868465f92f2ecee8c5" data-ratio="1.77777777777778" src="http://momota.github.io//speakerdeck.com/assets/embed.js"></script>


<ul>
<li>発表者: <a href="https://twitter.com/d_date">Daiki Matsudate(@d_date)さん</a></li>
<li>資料: <a href="https://speakerdeck.com/d_date/cloud-functionskarashi-merufirebase-4568e784-5bf3-4611-90a4-2f8632b3aa78">Cloud Functionsから始めるFirebase &ndash; Speaker Deck</a></li>
</ul>


<h4>Firebase</h4>

<ul>
<li>mBaaS

<ul>
<li>アプリ開発を容易に</li>
<li>アプリ品質向上</li>
</ul>
</li>
</ul>


<h4>Cloud Functions for Firebase</h4>

<ul>
<li>コードをクラウドにプッシュするとFirebaseのサービスのアクションをトリガーに動く</li>
</ul>


<h4>Admin API</h4>

<ul>
<li>CLIで特権環境からFirebaseを操作できる</li>
</ul>


<h4>ユースケース</h4>

<ul>
<li>(Twitterなどの)フォロワーが追加されたら通知する</li>
<li>メッセージのサニタイズする</li>
<li>画像をストレージにアップロード後、サムネイル化し格納し直し</li>
<li>URL Shorter</li>
<li>Firestoreの全文検索: Firestoreアップデート時にalgoliaにインデックスを貼る</li>
<li>Remote Config</li>
<li><a href="https://github.com/firebase/functions-samples">firebase/functions-samples： Collection of sample apps showcasing popular use cases using Cloud Functions for Firebase</a> にいろいろとサンプルがある</li>
</ul>


<h4>GCP</h4>

<ul>
<li>GCP FunctionsはGo 1.11に対応</li>
</ul>


<h3>Starting Google Kubernetes Engine 2019</h3>

<script async class="speakerdeck-embed" data-slide="1" data-id="4d31ff24e0cc4e79b5275dbaba4a49f3" data-ratio="1.77777777777778" src="http://momota.github.io//speakerdeck.com/assets/embed.js"></script>


<ul>
<li>発表者: <a href="https://twitter.com/sakajunquality">sakajunquality(@sakajunquality)さん</a></li>
<li>資料: <a href="https://speakerdeck.com/sakajunquality/starting-google-kubernetes-engine-2019">Starting Google Kubernetes Engine 2019 &ndash; Speaker Deck</a></li>
</ul>


<h4>What&rsquo;s k8s?</h4>

<ul>
<li>Borgベースのコンテナプラットフォーム</li>
<li>Microservicesプラットフォーム</li>
<li>Goベース</li>
<li>CNCFプロジェクトの「Graduated」ステージ</li>
</ul>


<h4>K8s マネージドサービス</h4>

<ul>
<li>GKE</li>
<li>EKS</li>
<li>AKS</li>
<li>IKS</li>
<li>などなどたくさんある…</li>
</ul>


<h4>Why GKE?</h4>

<ul>
<li>すでにGCPを使っている</li>
<li>k8sはむずかしい</li>
<li>GCP独自の機能</li>
</ul>


<h4>Already Using GCP?</h4>

<p>GCPでk8sを使うには以下のパターンがある</p>

<ul>
<li>AppEngine (Flexible) → 柔軟性がない</li>
<li>Compute Engine →  信頼性 (可用性) がない、作り込むとしても大変</li>
<li>Kubernetes Engine: Flexible + Reliable</li>
</ul>


<h4>k8sは難しい</h4>

<ul>
<li><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">kelseyhightower/kubernetes-the-hard-way： Bootstrap Kubernetes the hard way on Google Cloud Platform. No scripts.</a></li>
<li>k8s は構築も、維持も、管理も大変

<ul>
<li>Boosting</li>
<li>High Availability</li>
<li>Version Updates</li>
</ul>
</li>
<li>簡単にクラスタをつくるならフルマネージドのGKE</li>
</ul>


<h4>GKEはフルマネージドサービス</h4>

<ul>
<li>コントロールプレーンとワーカーノードが両方フルマネージド</li>
<li>リージョン・ゾーンレベルの可用性</li>
<li>Auto-Repair / Auto-Update</li>
<li>VPCネイティブ</li>
</ul>


<h4>GCP特有機能</h4>

<ul>
<li>Networking

<ul>
<li>Cloud Load Balancing: L4. L7</li>
<li>Cloud Armor: L3-L7カスタムルールを作れるWAF</li>
<li>Cloud CDN: グローバルCDN</li>
</ul>
</li>
<li>CI/CD

<ul>
<li>Cloud Build: フルマネージドCI、ネイティブDockerをサポート</li>
<li>Container Registry: Docker レジストリ。脆弱性診断が可能</li>
<li>Cloud Source Repository: プライベートGitリポジトリ。検索が強い。Githubからミラー可能。</li>
<li>GitOpsの概念</li>
</ul>
</li>
<li>Monitoring

<ul>
<li>Stackdriver Monitoring: フルスタックの監視スイート</li>
<li>Stackdriver Logging: フルマネージドログプラットフォーム。GKEはfluentdがプリインストール</li>
</ul>
</li>
<li>Integrations

<ul>
<li>Cloud Pub/Sub</li>
<li>Cloud Functions</li>
<li>Cloud IAP</li>
</ul>
</li>
</ul>


<h4>GKE Update</h4>

<ul>
<li>Private Cluster + Cloud Nat

<ul>
<li>Private Clusterは、プライベートIPだけを持てる</li>
<li>Cloud Natは、フルマネージドNat-Gateway</li>
</ul>
</li>
<li>NEG /Container-Native Load Balancing

<ul>
<li>Network Endpoint Groupを使うとLB～Pod間のトラフィック制御をiptablesを使わずにできる</li>
</ul>
</li>
<li>Node Auto-Provisioning

<ul>
<li>Cluster Autoscalerが新しいノードプールを作成・削除してくれる</li>
</ul>
</li>
<li>Binary Authorization

<ul>
<li>信頼できるイメージのみをGKEへデプロイできる</li>
<li>チェックボックスにチェックを入れるだけで有効化可能</li>
</ul>
</li>
<li>Istio

<ul>
<li>1クリックでIstioをデプロイ可能</li>
<li>既存クラスタにも適用可能</li>
</ul>
</li>
</ul>


<h4>How to start?</h4>

<ul>
<li><code>$ gcloud container clusters create MY_CLUSTER</code></li>
<li>本を読む

<ul>
<li>中井さんのプログラマのための Google Cloud Platform 入門</li>
<li>Docker/Kubernetes 実践コンテナ開発入門</li>
<li>青山さんのKubernetes完全ガイド</li>
</ul>
</li>
<li>ハンズオン

<ul>
<li>Quick Start</li>
<li>QwickLabs</li>
<li>Coursera</li>
<li>sakajunquality&rsquo;s hands-on</li>
</ul>
</li>
<li>オンラインドキュメント

<ul>
<li>GKE document</li>
<li>Kubernetes document</li>
<li>Youtubeもある</li>
</ul>
</li>
</ul>


<h3>Web in 2019 What’s coming?</h3>

<ul>
<li>発表者: <a href="https://twitter.com/laco2net">Suguru Inatomi / lacolaco(@laco2net)さん</a></li>
<li>資料: <a href="https://docs.google.com/presentation/d/e/2PACX-1vRXfgnXlYSQ5Q3ImC1DQoub0L_5NUrha9yW3MLcDnFbn1A-mdEXZF11wzzadDF2yKoUnroZ46tMwUl3/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p">20190130 &ndash; Web in 2019 What’s coming? &ndash; Google Slides</a></li>
</ul>


<h4>ES 2019 (WIP)</h4>

<ul>
<li><a href="https://qiita.com/tonkotsuboy_com/items/07f8ef98abf89250b90c">JavaScriptの次の仕様ES2019でほぼ確実に追加される新機能まとめ &ndash; Qiita</a></li>
</ul>


<h4>Web Components / Polymer</h4>

<ul>
<li>Polymerの追加開発がなくなった (メンテナンス状態)</li>
<li>lit

<ul>
<li>lit-html / lit-element</li>
</ul>
</li>
<li>Web ComponentsのBrowser supports Update

<ul>
<li>Firefox がサポート</li>
<li>EdgeがChromiumへ移行なので、移行後はEdgeでもwebcomponentsが使える</li>
</ul>
</li>
<li>CSS Shadow parts

<ul>
<li>Shadow DOM内にPartsを定義</li>
<li>外側のCSSから上書きできる</li>
</ul>
</li>
<li>Constructable Stylesheets

<ul>
<li>CSSStyleSheet()のオブジェクトを作成可能</li>
</ul>
</li>
<li>HTML Modules

<ul>
<li>Edgeチームから提案</li>
<li>.htm (モジュールファイル) をインポート可能</li>
</ul>
</li>
<li>Class Public Fields</li>
</ul>


<h4>Angular Updates</h4>

<ul>
<li>Community

<ul>
<li>成長中</li>
<li>Angular docsへの訪問者は1.5M に迫る</li>
<li>日本コミュニティ (ドキュメント翻訳など) も10,000MAUに到達</li>
</ul>
</li>
<li>Core updates

<ul>
<li>半年に1回メジャーアップデート</li>
<li>メジャーバージョンアップしてもそんなに大きな変化はなし</li>
</ul>
</li>
<li>Angular Bazel

<ul>
<li>Bazel (ビルドツール) をAngularでもサポート</li>
</ul>
</li>
<li>Ivy roadmap

<ul>
<li>次世代の内部リファクタリング</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
</feed>
